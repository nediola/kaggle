{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d188f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from configparser import ConfigParser\n",
    "\n",
    "RANDOM_STATE=123\n",
    "\n",
    "FEATURES = ['est_diameter_min', 'est_diameter_max', 'relative_velocity',\n",
    "            'miss_distance', 'absolute_magnitude']\n",
    "LABEL = 'hazardous'\n",
    "COLUMNS =  ['id', 'name'] + FEATURES + [LABEL]\n",
    "\n",
    "parser = ConfigParser()\n",
    "parser.read('pass.cfg')\n",
    "mysql_pass = parser.get('mysql', 'password')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967b62e",
   "metadata": {},
   "source": [
    "#### Split dataset into train/test to fit CatBoost and GBTClassifier models in the same conditions\n",
    "- stratified by classes\n",
    "- use SMOTE to oversampling positive examples\n",
    "- ignore sentry_object feature, because it always equals 0\n",
    "- ignore orbiting_body feature, because it always equals 'Earth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "554c5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = mysql.connector.connect(user=\"root\", password=mysql_pass)\n",
    "db_cursor = db_connection.cursor()\n",
    "db_cursor.execute('USE NeoDB;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9691e207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 81752, positive: 7956/9.732%\n",
      "Test set: 9084, positive: 884/9.731%\n",
      "--\n",
      "Train set with oversampling: 147592, positive: 73796/50.0%\n"
     ]
    }
   ],
   "source": [
    "db_cursor.execute(f'SELECT {\",\".join(COLUMNS)} FROM Neo')\n",
    "df = pd.DataFrame(db_cursor.fetchall())\n",
    "df.columns = COLUMNS\n",
    "\n",
    "X_train, X_test, _, _ = train_test_split(df[COLUMNS], df[LABEL], test_size=0.1,\n",
    "                                         stratify=df[LABEL], random_state=RANDOM_STATE)\n",
    "\n",
    "n_train, n_train_pos  = X_train.shape[0], sum(X_train.hazardous)\n",
    "print(f'Train set: {n_train}, positive: {n_train_pos}/{np.round(n_train_pos/n_train*100, 3)}%')\n",
    "n_test, n_test_pos  = X_test.shape[0], sum(X_test.hazardous)\n",
    "print(f'Test set: {n_test}, positive: {n_test_pos}/{np.round(n_test_pos/n_test*100, 3)}%')\n",
    "\n",
    "# Do oversampling for train set\n",
    "sm = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_aug, y_train_aug = sm.fit_resample(X_train[FEATURES], X_train.hazardous)\n",
    "X_train_aug['hazardous'] = y_train_aug\n",
    "print('--')\n",
    "n_train_aug, n_train_aug_pos  = X_train_aug.shape[0], sum(X_train_aug.hazardous)\n",
    "print(f'Train set with oversampling: \\\n",
    "{n_train_aug}, positive: {n_train_aug_pos}/{np.round(n_train_aug_pos/n_train_aug * 100, 3)}%')\n",
    "\n",
    "def df2mysqlstring(df):\n",
    "    tuples = list(df.itertuples(index=False, name=None))\n",
    "    return ','.join(['(' + ','.join([str(w) for w in t]) + ')' for t in tuples])\n",
    "\n",
    "train_table = 'NeoTrain'\n",
    "db_cursor.execute(f'DROP TABLE IF EXISTS {train_table}')\n",
    "db_cursor.execute(\n",
    "    f'CREATE TABLE {train_table} (\\\n",
    "    est_diameter_min FLOAT, est_diameter_max FLOAT, relative_velocity FLOAT, \\\n",
    "    miss_distance FLOAT, absolute_magnitude FLOAT, hazardous BOOLEAN);'\n",
    ")\n",
    "db_cursor.execute(\n",
    "    f'INSERT INTO {train_table} (\\\n",
    "    est_diameter_min, est_diameter_max, relative_velocity, \\\n",
    "    miss_distance, absolute_magnitude, hazardous) VALUES ' + df2mysqlstring(X_train_aug) + ';')\n",
    "db_cursor.execute('FLUSH TABLES;')\n",
    "\n",
    "test_table = 'NeoTest'\n",
    "X_test.name = '\"' + X_test.name + '\"'\n",
    "db_cursor.execute(f'DROP TABLE IF EXISTS {test_table}')\n",
    "db_cursor.execute(\n",
    "    f'CREATE TABLE {test_table} (\\\n",
    "    id INT, name VARCHAR(1000), est_diameter_min FLOAT, est_diameter_max FLOAT, relative_velocity FLOAT, \\\n",
    "    miss_distance FLOAT, absolute_magnitude FLOAT, hazardous BOOLEAN);'\n",
    ")\n",
    "db_cursor.execute(\n",
    "    f'INSERT INTO {test_table} (\\\n",
    "    id, name, est_diameter_min, est_diameter_max, relative_velocity, \\\n",
    "    miss_distance, absolute_magnitude, hazardous) VALUES ' + df2mysqlstring(X_test) + ';')\n",
    "db_cursor.execute('FLUSH TABLES;')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d038b",
   "metadata": {},
   "source": [
    "#### Train CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bf57c",
   "metadata": {},
   "source": [
    "Load train/test data from MySQL, split train data into the train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3e851ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cursor.execute(f'SELECT {\",\".join(FEATURES + [\"hazardous\"])} FROM NeoTrain')\n",
    "X_train = pd.DataFrame(db_cursor.fetchall())\n",
    "X_train.columns = FEATURES + [\"hazardous\"]\n",
    "\n",
    "db_cursor.execute(f'SELECT {\",\".join(COLUMNS)} FROM NeoTest')\n",
    "X_test = pd.DataFrame(db_cursor.fetchall())\n",
    "X_test.columns = COLUMNS\n",
    "y_test = X_test.hazardous\n",
    "\n",
    "X_val = X_train.iloc[:X_test.shape[0]]\n",
    "y_val = X_val.hazardous\n",
    "X_train = X_train.iloc[X_test.shape[0]:]\n",
    "y_train = X_train.hazardous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f27788a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive values: 884, found positive values: 1188\n",
      "Precision: 0.42845\n",
      "Recall: 0.57579\n",
      "F1: 0.49131\n"
     ]
    }
   ],
   "source": [
    "def print_all_metrics(y_true, y_pred):\n",
    "    print(f'True positive values: {sum(y_true)}, found positive values: {sum(y_pred)}')\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    print(f'Precision: {np.round(precision, 5)}')\n",
    "    print(f'Recall: {np.round(recall, 5)}')\n",
    "    print(f'F1: {np.round(f1, 5)}')\n",
    "\n",
    "model_catboost = CatBoostClassifier(iterations=10000)\n",
    "model_catboost.fit(X_train[FEATURES], y_train, eval_set=(X_val[FEATURES], y_val), verbose=False)\n",
    "y_pred_catboost = model_catboost.predict(X_test[FEATURES])\n",
    "print_all_metrics(y_test, y_pred_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908cbb9f",
   "metadata": {},
   "source": [
    "Save CatBoost results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "40786165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and archive parquet files\n",
    "prediction_df = X_test.copy()\n",
    "prediction_df['y_pred'] = y_pred_catboost\n",
    "outdir = './data/catboost_prediction'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "prediction_df.to_parquet('data/catboost_prediction/result')\n",
    "shutil.make_archive('data/catboost_prediction', 'zip', 'data/catboost_prediction')\n",
    "\n",
    "# Save to MySQL table\n",
    "table='NeoCatBoostResult'\n",
    "db_cursor.execute(f'DROP TABLE IF EXISTS {table}')\n",
    "db_cursor.execute(\n",
    "    f'CREATE TABLE IF NOT EXISTS {table}(\\\n",
    "     id INT, name VARCHAR(1000), est_diameter_min FLOAT, \\\n",
    "     est_diameter_max FLOAT, relative_velocity FLOAT, \\\n",
    "     miss_distance FLOAT, absolute_magnitude FLOAT, \\\n",
    "     hazardous BOOLEAN, y_pred BOOLEAN);'\n",
    ")\n",
    "prediction_df.name = '\"' + prediction_df.name + '\"'\n",
    "tuples = list(prediction_df.itertuples(index=False, name=None))\n",
    "tuples_string = ','.join(['(' + ','.join([str(w) for w in t]) + ')' for t in tuples])\n",
    "\n",
    "db_cursor.execute(\n",
    "    f'INSERT INTO {table} (\\\n",
    "    id, name, est_diameter_min, est_diameter_max, relative_velocity, \\\n",
    "    miss_distance, absolute_magnitude, hazardous, y_pred) VALUES ' + tuples_string + ';')\n",
    "db_cursor.execute('FLUSH TABLES;')\n",
    "\n",
    "# Save model\n",
    "model_catboost.save_model('models/model_catboost.cbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef894109",
   "metadata": {},
   "source": [
    "#### Train GBTClassifier [PySpark]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f93c7a",
   "metadata": {},
   "source": [
    "Load train/test data from MySQL, split train data into the train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4e6380c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "os.environ['JAVA_HOME'] = '/opt/homebrew/opt/openjdk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f77fcfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mysql2pyspark_df(builder, db, table, mysql_user, mysql_pass):\n",
    "    return spark.read.format('jdbc').option('url', f'jdbc:mysql://localhost:3306/{db}') \\\n",
    "    .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "    .option('dbtable', table) \\\n",
    "    .option('user', mysql_user).option('password', mysql_pass).load()\n",
    "\n",
    "spark = SparkSession.builder.appName('Neo')\\\n",
    ".config('spark.jars', 'mysql-connector-java-8.0.30/mysql-connector-java-8.0.30.jar').getOrCreate()\n",
    "\n",
    "df_train = mysql2pyspark_df(spark, 'NeoDB', 'NeoTrain', 'root', mysql_pass)\n",
    "df_train = df_train.withColumn('hazardous', df_train.hazardous.cast('float'))\n",
    "df_test = mysql2pyspark_df(spark, 'NeoDB', 'NeoTest', 'root', mysql_pass)\n",
    "df_test = df_test.withColumn('hazardous', df_test.hazardous.cast('float'))\n",
    "\n",
    "# Split train on train/val:\n",
    "df_train = df_train.withColumn('index', monotonically_increasing_id())\n",
    "df_val = df_train.limit(df_test.count())\n",
    "df_val = df_train.where(df_train.index < df_test.count())\n",
    "df_val = df_val.withColumn('valIndicator', lit(True))\n",
    "df_train = df_train.where(df_train.index >= df_test.count())\n",
    "df_train = df_train.withColumn('valIndicator', lit(False))\n",
    "df_train_val = df_train.union(df_val)\n",
    "\n",
    "X_train_val_vec = VectorAssembler(inputCols=FEATURES + ['valIndicator'],\n",
    "                                  outputCol=\"features\").transform(df_train_val)\n",
    "X_test_vec = VectorAssembler(inputCols=FEATURES, outputCol='features').transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4830bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_clf = GBTClassifier(labelCol='hazardous', featuresCol='features').setValidationIndicatorCol('valIndicator')\n",
    "model_gbt = gbt_clf.fit(X_train_val_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fe444807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+\n",
      "|      name|prediction|hazardous|\n",
      "+----------+----------+---------+\n",
      "|(2021 CR1)|       0.0|      0.0|\n",
      "|(2019 XN2)|       0.0|      0.0|\n",
      "| (2016 JE)|       1.0|      0.0|\n",
      "|(2018 MG7)|       1.0|      1.0|\n",
      "|(2019 GV5)|       0.0|      0.0|\n",
      "+----------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_gbt = model_gbt.transform(X_test_vec)\n",
    "y_pred_gbt.select('name', 'prediction', 'hazardous').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "913c77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive values: 884.0, found positive values: 2734.0\n",
      "Precision: 0.31346\n",
      "Recall: 0.96946\n",
      "F1: 0.47374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 538:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def print_all_metrics_spark(df_with_pred):\n",
    "    dd = df_with_pred.rdd\n",
    "    scoreAndLabels = dd.map(lambda t: (t.prediction, t.hazardous))\n",
    "    metrics = MulticlassMetrics(scoreAndLabels)\n",
    "    y_true = df_with_pred.agg({'hazardous': 'sum'}).collect()[0][0]\n",
    "    y_pred = df_with_pred.agg({'prediction': 'sum'}).collect()[0][0]\n",
    "    print(f'True positive values: {y_true}, found positive values: {y_pred}')\n",
    "    print(f'Precision: {np.round(metrics.precision(1.0), 5)}')\n",
    "    print(f'Recall: {np.round(metrics.recall(1.0), 5)}')\n",
    "    print(f'F1: {np.round(metrics.fMeasure(1.0), 5)}')\n",
    "\n",
    "print_all_metrics_spark(y_pred_gbt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
