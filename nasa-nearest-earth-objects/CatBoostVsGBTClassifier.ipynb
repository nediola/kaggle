{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d188f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from configparser import ConfigParser\n",
    "\n",
    "RANDOM_STATE=123\n",
    "\n",
    "FEATURES = ['est_diameter_min', 'est_diameter_max', 'relative_velocity',\n",
    "            'miss_distance', 'absolute_magnitude']\n",
    "LABEL = 'hazardous'\n",
    "COLUMNS =  ['id', 'name'] + FEATURES + [LABEL]\n",
    "\n",
    "MYSQL_DB = 'NeoDB'\n",
    "MYSQL_DS = 'Neo'\n",
    "MYSQL_TRAIN_DS = 'NeoTrain'\n",
    "MYSQL_TEST_DS = 'NeoTest'\n",
    "MYSQL_CATBOOST_RESULT = 'NeoCatBoostResult'\n",
    "MYSQL_GBT_RESULT = 'NeoGBTResult'\n",
    "\n",
    "parser = ConfigParser()\n",
    "parser.read('pass.cfg')\n",
    "mysql_login = 'root'\n",
    "mysql_pass = parser.get('mysql', 'password')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce374b",
   "metadata": {},
   "source": [
    "Helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e29c6822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2sqlstring(df):\n",
    "    '''Concatenates dataframe rows into a single-string, compatible to SQL-syntax'''\n",
    "    tuples = list(df.itertuples(index=False, name=None))\n",
    "    return ','.join(['(' + ','.join([str(w) for w in t]) + ')' for t in tuples])\n",
    "\n",
    "def mysql2pandas_df(db, table, mysql_user, mysql_pass, columns):\n",
    "    '''Loads MySQL table to pandas dataframe'''\n",
    "    db_connection = mysql.connector.connect(user=mysql_login, password=mysql_pass)\n",
    "    db_cursor = db_connection.cursor()\n",
    "    db_cursor.execute(f'USE {db}')\n",
    "    db_cursor.execute(f'SELECT {\",\".join(columns)} FROM {table}')\n",
    "    df = pd.DataFrame(db_cursor.fetchall())\n",
    "    df.columns = columns\n",
    "    db_cursor.close()\n",
    "    db_connection.close()\n",
    "    return df    \n",
    "    \n",
    "def pandas_df2mysql(df, db, table, mysql_user, mysql_pass, col_types):\n",
    "    '''Loads pandas dataframe to mysql table'''\n",
    "    columns = ', '.join(df.columns)\n",
    "    columns_and_types = ', '.join([f'{df.columns[i]} {col_types[i]}' for i in range(len(df.columns))])\n",
    "    db_connection = mysql.connector.connect(user=mysql_login, password=mysql_pass)\n",
    "    db_cursor = db_connection.cursor()\n",
    "    db_cursor.execute(f'USE {db}')\n",
    "    db_cursor.execute(f'DROP TABLE IF EXISTS {table}')\n",
    "    db_cursor.execute(f'CREATE TABLE {table}({columns_and_types});');\n",
    "    db_cursor.execute(f'INSERT INTO {table} ({columns}) VALUES ' + df2sqlstring(df) + ';')\n",
    "    db_cursor.execute('FLUSH TABLES;')\n",
    "    db_cursor.close()\n",
    "    db_connection.close()\n",
    "\n",
    "def mysql2pyspark_df(builder, db, table, mysql_user, mysql_pass):\n",
    "    '''Loads MySQL table to pyspark dataframe'''\n",
    "    return builder.read.format('jdbc').option('url', f'jdbc:mysql://localhost:3306/{db}') \\\n",
    "    .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "    .option('dbtable', table) \\\n",
    "    .option('user', mysql_user).option('password', mysql_pass).load()\n",
    "\n",
    "def pyspark_df2mysql(df, db, table, mysql_user, mysql_pass):\n",
    "    '''Loads pyspark dataframe to mysql table'''\n",
    "    return df.write.format('jdbc').option('url', f'jdbc:mysql://localhost:3306/{db}') \\\n",
    "    .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "    .option('dbtable', table) \\\n",
    "    .option('user', mysql_user).option('password', mysql_pass).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32fa317",
   "metadata": {},
   "source": [
    "#### Split the dataset into train/test to fit the CatBoost and GBTClassifier models in the same conditions\n",
    "- downsample negative examples\n",
    "- stratify\n",
    "- ignore sentry_object feature, because it always equals 0\n",
    "- ignore orbiting_body feature, because it always equals 'Earth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9691e207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 15912, positive: 7956/50.0%\n",
      "Test set: 1768, positive: 884/50.0%\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and split to train/test\n",
    "df = mysql2pandas_df(MYSQL_DB, MYSQL_DS, mysql_login, mysql_pass, COLUMNS)\n",
    "\n",
    "# Balance positive and negative examples\n",
    "df1 = df[df.hazardous == 1]\n",
    "df2 = df[df.hazardous == 0].sample(frac=1).head(df1.shape[0])\n",
    "df = pd.concat([df1, df2], axis=0).sample(frac=1)\n",
    "\n",
    "X_train, X_test, _, _ = train_test_split(df[COLUMNS], df[LABEL], test_size=0.1,\n",
    "                                         stratify=df[LABEL], random_state=RANDOM_STATE)\n",
    "\n",
    "n_train, n_train_pos  = X_train.shape[0], sum(X_train[LABEL])\n",
    "print(f'Train set: {n_train}, positive: {n_train_pos}/{np.round(n_train_pos/n_train*100, 3)}%')\n",
    "n_test, n_test_pos  = X_test.shape[0], sum(X_test[LABEL])\n",
    "print(f'Test set: {n_test}, positive: {n_test_pos}/{np.round(n_test_pos/n_test*100, 3)}%')\n",
    "\n",
    "# Load train/test datasets back to MySQL\n",
    "column_types = ['INT', 'VARCHAR(1000)'] + ['FLOAT'] * 5 + ['BOOLEAN']\n",
    "X_train.name = '\"' + X_train.name + '\"'\n",
    "pandas_df2mysql(X_train, MYSQL_DB, MYSQL_TRAIN_DS, mysql_login, mysql_pass, column_types)\n",
    "X_test.name = '\"' + X_test.name + '\"'\n",
    "pandas_df2mysql(X_test, MYSQL_DB, MYSQL_TEST_DS, mysql_login, mysql_pass, column_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d038b",
   "metadata": {},
   "source": [
    "#### Train CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2320b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, fbeta_score\n",
    "from sklearn.metrics import make_scorer, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfb7a4",
   "metadata": {},
   "source": [
    "Load train/test data from MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e851ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mysql2pandas_df(MYSQL_DB, MYSQL_TRAIN_DS, mysql_login, mysql_pass, COLUMNS)\n",
    "y_train = X_train[LABEL]\n",
    "X_test = mysql2pandas_df(MYSQL_DB, MYSQL_TEST_DS, mysql_login, mysql_pass, COLUMNS)\n",
    "y_test = X_test[LABEL]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83775fd",
   "metadata": {},
   "source": [
    "Optimize CatBoost hyperparameters: depth, l2_leaf_reg (5 folds)\n",
    "\n",
    "The evaluation metric is F-beta (beta=2, recall is more important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5256748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost best score: 0.9433070467418461\n",
      "CatBoost best parameters: {'depth': 2, 'iterations': 1000, 'l2_leaf_reg': 5, 'random_seed': 123, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "catboost_params = {\n",
    "    'iterations': [1000],\n",
    "    'verbose': [False],\n",
    "    'depth': [2, 3, 4, 5],\n",
    "    'l2_leaf_reg': [3, 4, 5],\n",
    "    'random_seed': [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "catboost_clf = CatBoostClassifier()\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=2)\n",
    "grid_catboost = GridSearchCV(estimator=catboost_clf, param_grid=catboost_params, cv=5,\n",
    "                             scoring=fbeta_scorer, n_jobs=-1)\n",
    "grid_catboost.fit(X_train[FEATURES], y_train)\n",
    "\n",
    "best_catboost_params = grid_catboost.best_params_\n",
    "print(f'CatBoost best score: {grid_catboost.best_score_}')\n",
    "print(f'CatBoost best parameters: {best_catboost_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fae959",
   "metadata": {},
   "source": [
    "Calculate precision, recall, f1, f-beta to understand results better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51e3e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-metrics\n",
      "[precision] test avg score: 0.8045\n",
      "[recall] test avg score: 0.983\n",
      "[f1] test avg score: 0.8849\n",
      "[f-beta] test avg score: 0.9413\n"
     ]
    }
   ],
   "source": [
    "scoring = {\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'f-beta': make_scorer(fbeta_score, beta=2)\n",
    "}\n",
    "\n",
    "# Calculate precision, recall, f1 and f-beta on cross-validation\n",
    "catboost_clf = CatBoostClassifier(depth=2, iterations=1000, l2_leaf_reg=5,\n",
    "                                  verbose=False, random_seed=RANDOM_STATE)\n",
    "scores = cross_validate(catboost_clf, X_train[FEATURES], y_train,\n",
    "                        cv=5, n_jobs=-1, scoring=scoring)\n",
    "print('CV-metrics')\n",
    "for m in scoring.keys():\n",
    "    test_avg_score = np.round(np.mean(scores['test_' + m][0]), 4)\n",
    "    print(f'[{m}] test avg score: {test_avg_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70c3f1",
   "metadata": {},
   "source": [
    "Calculate prediction for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a21b5ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hazardous asteroids: 884\n",
      "Found TP hazardous asteroids: 868\n",
      "Found FP hazardous asteroids: 220\n",
      "Precision: 0.7978\n",
      "Recall: 0.9819\n",
      "f1: 0.8803\n",
      "f-beta: 0.9386\n"
     ]
    }
   ],
   "source": [
    "best_catboost_model = CatBoostClassifier(depth=2, iterations=1000, l2_leaf_reg=5, verbose=False,\n",
    "                                         random_seed=RANDOM_STATE)\n",
    "best_catboost_model.fit(X_train[FEATURES], y_train)\n",
    "y_pred_catboost = best_catboost_model.predict(X_test[FEATURES])\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_catboost).ravel()\n",
    "print(f'Hazardous asteroids: {np.sum(y_test)}')\n",
    "print(f'Found TP hazardous asteroids: {tp}')\n",
    "print(f'Found FP hazardous asteroids: {fp}')\n",
    "print(f'Precision: {np.round(precision_score(y_test, y_pred_catboost), 4)}')\n",
    "print(f'Recall: {np.round(recall_score(y_test, y_pred_catboost), 4)}')\n",
    "print(f'f1: {np.round(f1_score(y_test, y_pred_catboost), 4)}')\n",
    "print(f'f-beta: {np.round(fbeta_score(y_test, y_pred_catboost, beta=2), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908cbb9f",
   "metadata": {},
   "source": [
    "Save CatBoost results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40786165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and archive parquet files\n",
    "prediction_df = X_test.copy()\n",
    "prediction_df['y_pred'] = y_pred_catboost\n",
    "outdir = './data/catboost_prediction'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "prediction_df.to_parquet('data/catboost_prediction/result')\n",
    "shutil.make_archive('data/catboost_prediction', 'zip', 'data/catboost_prediction')\n",
    "\n",
    "# Save to MySQL table\n",
    "column_types_prediction = ['INT', 'VARCHAR(1000)'] + ['FLOAT'] * 5 + ['BOOLEAN'] * 2\n",
    "prediction_df.name = '\"' + prediction_df.name + '\"'\n",
    "pandas_df2mysql(prediction_df, MYSQL_DB, MYSQL_CATBOOST_RESULT, mysql_login, mysql_pass, column_types_prediction)\n",
    "\n",
    "# Save model\n",
    "best_catboost_model.save_model('models/model_catboost.cbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef894109",
   "metadata": {},
   "source": [
    "#### Train GBTClassifier [PySpark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90302769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "os.environ['JAVA_HOME'] = '/opt/homebrew/opt/openjdk/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c0543",
   "metadata": {},
   "source": [
    "Load train/test data from MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f77fcfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Neo')\\\n",
    ".config('spark.jars', 'mysql-connector-java-8.0.30/mysql-connector-java-8.0.30.jar').getOrCreate()\n",
    "\n",
    "df_train = mysql2pyspark_df(spark, MYSQL_DB, MYSQL_TRAIN_DS, mysql_login, mysql_pass)\n",
    "df_train = df_train.withColumn('hazardous', df_train.hazardous.cast('float'))\n",
    "df_test = mysql2pyspark_df(spark, MYSQL_DB, MYSQL_TEST_DS, mysql_login, mysql_pass)\n",
    "df_test = df_test.withColumn('hazardous', df_test.hazardous.cast('float'))\n",
    "\n",
    "assembler = VectorAssembler(inputCols=FEATURES, outputCol='features')\n",
    "X_train_vec = assembler.transform(df_train)\n",
    "X_test_vec = assembler.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb34809",
   "metadata": {},
   "source": [
    "Optimize GBTClassifier hyperparameters: minInstancesPerNode, maxDepth, maxBins (5 folds)\n",
    "\n",
    "The evaluation metric is F-beta (beta=2, recall is more important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc208128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbt_clf = GBTClassifier(labelCol='hazardous', featuresCol='features')\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='weightedFMeasure', beta=2.0, labelCol='hazardous')\n",
    "grid = ParamGridBuilder() \\\n",
    "     .addGrid(gbt_clf.minInstancesPerNode, [1, 2, 3]) \\\n",
    "     .addGrid(gbt_clf.maxDepth, [2, 3, 4, 5]) \\\n",
    "     .addGrid(gbt_clf.maxBins, [16, 32, 64]) \\\n",
    "     .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=gbt_clf, estimatorParamMaps=grid,\n",
    "                          evaluator=evaluator, numFolds=5, seed=RANDOM_STATE)\n",
    "cv_gbt_model = crossval.fit(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "111d27b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT best AVG score: 0.8732904411279291\n",
      "GBT best parameters:\n",
      "\tminInstancesPerNode: 1\n",
      "\tmaxDepth: 5\n",
      "\tmaxBins: 16\n"
     ]
    }
   ],
   "source": [
    "model_gbt = cv_gbt_model.bestModel\n",
    "print(f'GBT best AVG score: {np.max(cv_gbt_model.avgMetrics)}')\n",
    "print(f'GBT best parameters:')\n",
    "print(f'\\tminInstancesPerNode: {model_gbt.getMinInstancesPerNode()}')\n",
    "print(f'\\tmaxDepth: {model_gbt.getMaxDepth()}')\n",
    "print(f'\\tmaxBins: {model_gbt.getMaxBins()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc57bd48",
   "metadata": {},
   "source": [
    "Calculate precision, recall, f1, f-beta to understand results better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4298513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-metrics\n",
      "[precision] test avg score: 0.9819\n",
      "[recall] test avg score: 0.7664\n",
      "[f1] test avg score: 0.8747\n",
      "[f-beta] test avg score: 0.873\n"
     ]
    }
   ],
   "source": [
    "def print_cv_metric(data, est, est_params, evaluator, metric_name, folds=5, seed=RANDOM_STATE):\n",
    "    cv_model = CrossValidator(estimator=est, estimatorParamMaps=est_params,\n",
    "                              evaluator=evaluator, numFolds=folds, seed=RANDOM_STATE).fit(data)\n",
    "    print(f'[{metric_name}] test avg score: {np.round(cv_model.avgMetrics, 4)[0]}')\n",
    "\n",
    "gbt_clf = GBTClassifier(labelCol='hazardous', featuresCol='features')\n",
    "grid = ParamGridBuilder() \\\n",
    "     .addGrid(gbt_clf.minInstancesPerNode, [3]) \\\n",
    "     .addGrid(gbt_clf.maxDepth, [5]) \\\n",
    "     .addGrid(gbt_clf.maxBins, [16]) \\\n",
    "     .build()\n",
    "eval_precision = MulticlassClassificationEvaluator(metricName='precisionByLabel', labelCol='hazardous')\n",
    "eval_recall = MulticlassClassificationEvaluator(metricName='recallByLabel', labelCol='hazardous')\n",
    "eval_f1 = MulticlassClassificationEvaluator(metricName='f1', labelCol='hazardous')\n",
    "eval_fbeta = MulticlassClassificationEvaluator(metricName='weightedFMeasure', beta=2.0, labelCol='hazardous')\n",
    "\n",
    "print('CV-metrics')\n",
    "print_cv_metric(X_train_vec, gbt_clf, grid, eval_precision, 'precision')\n",
    "print_cv_metric(X_train_vec, gbt_clf, grid, eval_recall, 'recall')\n",
    "print_cv_metric(X_train_vec, gbt_clf, grid, eval_f1, 'f1')\n",
    "print_cv_metric(X_train_vec, gbt_clf, grid, eval_fbeta, 'f-beta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470c168",
   "metadata": {},
   "source": [
    "Calculate prediction for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21ec1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------+\n",
      "|        name|prediction|hazardous|\n",
      "+------------+----------+---------+\n",
      "|  (2021 RH6)|       0.0|      0.0|\n",
      "|(2014 QX432)|       1.0|      1.0|\n",
      "|  (2015 YA1)|       0.0|      0.0|\n",
      "+------------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_gbt_model = GBTClassifier(labelCol='hazardous', featuresCol='features',\n",
    "                        minInstancesPerNode=3, maxDepth=5, maxBins=16)\n",
    "best_gbt_model = best_gbt_model.fit(X_train_vec)\n",
    "df_pred_gbt = best_gbt_model.transform(X_test_vec)\n",
    "df_pred_gbt.select('name', 'prediction', 'hazardous').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bda2c00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hazardous asteroids: 884\n",
      "Found TP hazardous asteroids: 871\n",
      "Found FP hazardous asteroids: 273\n",
      "Precision: 0.7976\n",
      "Recall: 0.9853\n",
      "f1: 0.88158\n",
      "f-beta: 0.864\n"
     ]
    }
   ],
   "source": [
    "scoreAndLabels = df_pred_gbt.rdd.map(lambda t: (t.prediction, t.hazardous))\n",
    "metrics = MulticlassMetrics(scoreAndLabels)\n",
    "y_true = int(df_pred_gbt.agg({'hazardous': 'sum'}).collect()[0][0])\n",
    "y_pred = int(df_pred_gbt.agg({'prediction': 'sum'}).collect()[0][0])\n",
    "tp = int(metrics.truePositiveRate(1.0) * y_true)\n",
    "fp = int(metrics.falsePositiveRate(1.0) * y_pred)\n",
    "print(f'Hazardous asteroids: {y_true}')\n",
    "print(f'Found TP hazardous asteroids: {tp}')\n",
    "print(f'Found FP hazardous asteroids: {fp}')\n",
    "print(f'Precision: {np.round(metrics.precision(1.0), 4)}')\n",
    "print(f'Recall: {np.round(metrics.recall(1.0), 4)}')\n",
    "print(f'f1: {np.round(metrics.fMeasure(1.0), 5)}')\n",
    "print(f'f-beta: {np.round(metrics.weightedFMeasure(2.0), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6ad5b",
   "metadata": {},
   "source": [
    "Save GBTClassifier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a55b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and archive parquet files\n",
    "out_dir = './data/gbt_prediction'\n",
    "df_pred_gbt.write.mode('overwrite').parquet(out_dir)\n",
    "shutil.make_archive(out_dir, 'zip', out_dir)\n",
    "\n",
    "# Save to MySQL table\n",
    "pyspark_df2mysql(df_pred_gbt.select(COLUMNS + ['prediction']), MYSQL_DB, MYSQL_GBT_RESULT, mysql_login, mysql_pass)\n",
    "\n",
    "# Save model\n",
    "model_gbt.save('models/model_gbt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
